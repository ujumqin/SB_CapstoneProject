{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Machine Learning\"\nauthor: \"Sine Gov\"\ndate: \"January 14, 2018\"\noutput:\n  pdf_document: default\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n```\n## Sentiment Predictor for Overwatch\nTo help alleviate the need to manually review every negative/toxic language customer service ticket, several prototype models that detects sentiment automatically has been created to determine which model will likely provide the best accuracy. The data set used to create the models was scrapped from reddit and the Overwatch forums. Each comment was then analyzed for negativity using two lexicons: afinn and bing and assigned a score accordingly. This score determined whether a comment was negative or positive and those results were recorded. \n\n## Type of Problem\nUsing the supervised method of classification and regression trees (CART), predictive models were created. Eighty percent of the data set was used for training the model and the remaining 20% of the data set was used to validate the model. The predictors used for these models are the comments themselves and the score for each of these comments determined via the seniment analyzers.\n\n## CART Models\nThe CART method was used to create this algorithm and the model was iterated on three times. The first model was created using the rpart's CART method with default values. The second model was created with cross validation of the CART method. The third model was created using the randomForest method of CART.\n\n## Evaluation\nIn the case of detecting toxic language, we want to make sure we are accurately capturing this behavior. The models were evaluated by computing the accuracy of the model using a confusion table. The higher our accuracy at identifing the toxic language, the better since we could get potentially remove these types of reports so our customer service reps can deal with higher priority/value tickets such as helping users gain access to hacked accounts or billing issues. \n\n## Results\nBelow the accuracy for each model by lexicon is shown. \n\n\\newpage\n### First Model (Default values with no validation)\nBelow we see that the afinn method for detecting negative language is more accurate for model 1. Accuracy is not as high as we would like, but this provides us a start.\n\nModel 1 Accuracy | bing | afinn\n---|---|---\nForums | 0.6877 | **0.7084**\nReddit | 0.6562 | **0.6988**\nForums & Reddit | 0.6688 | **0.722**\n\n### Second Model (Cross Validation for each with best fit cp value)\nWith Cross Validation we are able to improve the accuracy of the models. For the most part the afinn method is better at obtaining accuracy except for reddit data which outperformed the afinn model by 0.004. This discrepency could be due to the random sampling that made the bing model better at detecting negative sentiment. \n\nModel 2 Accuracy | bing | afinn\n---|---|---\nForums | 0.711 | **0.7414**\nReddit | **0.7094** | 0.705\nForums & Reddit | 0.7058 | **0.7525**\n\n\n### Third Model (random forest method)\nThe random forest method provided the best accuracy out of all three models. In this model, the afinn lexicon outperformed the bing lexicon.\n\nModel 3 Accuracy | bing | afinn\n---|---|---\nForums | 0.804 | **0.8072**\nReddit | 0.7844 | **0.8075**\nForums & Reddit | 0.7926 | **0.833**\n\n## Conclusion\nFrom these models, it is likely that the afinn lexicon combined with the randomforest method for CART may be the best tools to help us detect negative sentiment. Keep in mind that these models only used data scrapped from community sites and they were scored based on a lexicon that may have incorrectly identified certain keywords (kill, mercy, etc) that may be neutral in the discussion of Overwatch. Using customer service reports validated by our customer service staff, we could get a model that would contain true accuracy and could be employed to save our staff time and ultimately money if the accuracy was high enough. As of now, this model provides a proof of concept for consideration of the creation of a similiar model.\n\n\\newpage\n\n## Appendix\n### Full code for modeling\n```{r, eval=FALSE, message=FALSE, error=FALSE}\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(tm)\nlibrary(caTools)\nlibrary(rpart.plot)\nlibrary(e1071)\nlibrary(caret)\nlibrary(randomForest)\n\n#-------------------------Reading Files Into R-------------------------#\n#We are only interested in using reddit and forums data. Twitter was found to contain \n#irrelevant data.\n\n#read files into R. Ensure they are not factors\nforums <- read.csv(\"OWFORUMS12_22_FINAL.csv\", stringsAsFactors = FALSE)\nreddit <- read.csv(\"REDDIT_12_22_FINAL.csv\", stringsAsFactors = FALSE)\nforandred <- read.csv(\"OWFORUMS&REDDIT_12_22_FINAL.csv\", stringsAsFactors = FALSE)\n\n#-------------------------Tokenize Data-------------------------#\n#duplicating the text column so we have a copy of the text. \n#This gets destroyed during tokenization, but we need it to group by.\nforums$text_topic <- forums$text\nreddit$text_topic <- reddit$X.text.\nforandred$text_topic <- forandred$text\n\n#tokenize the text column and group by text of each comment (text_topic)\ntidy_forums <- forums %>%\n  group_by(text_topic) %>%\n  mutate(linenumber = row_number()) %>%\n  unnest_tokens(word, text) %>%\n  ungroup()\n\ntidy_reddit <- reddit %>%\n  group_by(text_topic) %>%\n  mutate(linenumber = row_number()) %>%\n  unnest_tokens(word, X.text.) %>%\n  ungroup()\n\ntidy_forandred <- forandred %>%\n  group_by(text_topic) %>%\n  mutate(linenumber = row_number()) %>%\n  unnest_tokens(word, text) %>%\n  ungroup()\n\n#-------------------------Bing Sentiment Function-------------------------#\n\n#bing maker is a function to get bing sentiment from tidy data\nbing_maker <- function(tidy_data) {\n  bing_data <- tidy_data %>%\n    inner_join(get_sentiments(\"bing\"))\n  \n  #create new columns to use in for loop calculations.\n  #we will calculate the sentiment score by adding \n  #all the sentiments and dividing by number of sentiments.\n  bing_data$score <- 0\n  bing_data$count <- 1\n  \n  #for loops codes the sentiment from bing sentiment into a -1 or 1. \n  #1 is positive and -1 is negative. \n  #Also counts the number of sentiment words to be used later.\n  for(i in 1:length(bing_data$sentiment)) {\n    if(bing_data$sentiment[i] == \"negative\") {\n      bing_data$score[i] = -1\n    } else {\n      bing_data$score[i] = 1\n    }\n  }\n  \n  #calculates the sentiment score by adding up all sentiment values \n  #and dividing it by the total for a single post. \n  #text_topic is used since it identifies if a word belongs to a single comment.\n  bing_data <- bing_data %>%\n    group_by(text_topic) %>%\n    mutate(sentimentscore = sum(score)/sum(count))\n  \n  #identify the negative values. used later to predict negative sentiment\n  bing_data$negative <- as.factor(bing_data$sentimentscore < 0)\n  \n  #collapse the duplicated columns by text_topic\n  bing_data <- bing_data[!duplicated(bing_data$text_topic),]\n  \n  bing_data <- data.frame(bing_data$text_topic, bing_data$sentimentscore, bing_data$negative)\n  names(bing_data) <- c(\"forum_text\",\"sentiment_score\",\"negative\")\n  return(bing_data)\n}\n\n#--------------------Perform bing--------------------#\nforum_bing <- bing_maker(tidy_forums)\nreddit_bing <- bing_maker(tidy_reddit)\nforandred_bing <- bing_maker(tidy_forandred)\n\n#-------------------------Afinn Sentiment Function-------------------------#\n#afinn maker is a function to get afinn sentiment from tidy data\nafinn_maker <- function(tidy_data) {\n  afinn_data <- tidy_data %>%\n    inner_join(get_sentiments(\"afinn\"))\n  \n  #create this column to help calculate sentiment score \n  afinn_data$count <- 1\n\n  #calculate sentiment score using afinn\n  afinn_data <- afinn_data %>%\n    group_by(text_topic) %>%\n    mutate(sentimentscore = sum(score)/sum(count))\n  \n  #collapse the duplicated columns by text_topic\n  afinn_data <- afinn_data[!duplicated(afinn_data$text_topic),]\n  \n  afinn_data <- data.frame(afinn_data$text_topic, afinn_data$sentimentscore)\n  names(afinn_data) <- c(\"forum_text\",\"sentiment_score\")\n  \n  afinn_data$negative <- 0\n  \n  #for loops codes the sentiment from bing sentiment into a -1 or 1.\n  #1 is positive and -1 is negative. \n  #Also counts the number of sentiment words to be used later.\n  for(i in 1:length(afinn_data$sentiment_score)) {\n    if(afinn_data$sentiment_score[i] < 0) {\n      afinn_data$negative[i] = \"TRUE\"\n    } else {\n      afinn_data$negative[i] = \"FALSE\"\n    }\n  }\n  \n  return(afinn_data)\n}\n\n#--------------------Perform afinn--------------------#\nforum_afinn <- afinn_maker(tidy_forums)\nforum_afinn$negative <- as.factor(forum_afinn$negative)\nreddit_afinn <- afinn_maker(tidy_reddit)\nreddit_afinn$negative <- as.factor(reddit_afinn$negative)\nforandred_afinn <- afinn_maker(tidy_forandred)\nforandred_afinn$negative <- as.factor(forandred_afinn$negative)\n\n#----------------PREP DATA FOR MACHINE LEARNING----------------#\n\n#----------------Corpus Maker----------------#\n#Function to reate a corpus and remove unnecessary words/text\n#sentiment_data should be the dataset created from bing or afinn maker above\ncorpus_maker <- function(sentiment_data) {\n  data_corpus <- Corpus(VectorSource(sentiment_data$forum_text))\n  data_corpus <- tm_map(data_corpus, removePunctuation)\n  data_corpus <- tm_map(data_corpus, tolower)\n  data_corpus <- tm_map(data_corpus, removeWords, stopwords(\"english\"))\n  data_corpus <- tm_map(data_corpus, stemDocument)\n  return(data_corpus)\n}\n\n#----------------Make Corpus----------------#\nbforum_corpus <- corpus_maker(forum_bing)\nbreddit_corpus <- corpus_maker(reddit_bing)\nbforandred_corpus <- corpus_maker(forandred_bing)\n\naforum_corpus <- corpus_maker(forum_afinn)\nareddit_corpus <- corpus_maker(reddit_afinn)\naforandred_corpus <- corpus_maker(forandred_afinn)\n\n\n#----------------Process Corpus Function----------------#\n#Function to process the corpus\n\nprocess_corpus <- function(corpus_name, bing_name) {\n  #Find frequencies of words\n  freq <- DocumentTermMatrix(corpus_name)\n  \n  #removing the sparse terms\n  sparse <- removeSparseTerms(freq, 0.995)\n  \n  #convert sparse data into a data frame\n  sparse <- as.data.frame(as.matrix(sparse))\n  \n  #converts variable names to appropriate names (some may start with numbers)\n  colnames(sparse) = make.names(colnames(sparse))\n  \n  #add dependent variable to the dataframe. We will be predicting this value.\n  sparse$negative <- bing_name$negative\n  return(sparse)\n}\n\n#----------------Processing Corpus----------------#\nb_forum_predict <- process_corpus(bforum_corpus, forum_bing)\nb_reddit_predict <- process_corpus(breddit_corpus, reddit_bing)\nb_forandred_predict <- process_corpus(bforandred_corpus, forandred_bing)\n\na_forum_predict <- process_corpus(aforum_corpus, forum_afinn)\na_reddit_predict <- process_corpus(areddit_corpus, reddit_afinn)\na_forandred_predict <- process_corpus(aforandred_corpus, forandred_afinn)\n\n#----------------Splitting into Test and Train Sets----------------#\n#setting a seed to get consistent results when running multiple times\nset.seed(1113)\n\n#split the data into a training set and a test set. \n\n#set the SplitRatio into variable so we can modify easily for all data sets. \n#This ratio will go into the test set (20% goes into test set)\nsr <- 0.2\n\n\n#Bing Forums\nbforum_split <- sample.split(b_forum_predict$negative, SplitRatio = sr)\nbforum_test <- subset(b_forum_predict, bforum_split == TRUE)\nbforum_train <- subset(b_forum_predict, bforum_split == FALSE)\n\n#Bing Reddit\nbreddit_split <- sample.split(b_reddit_predict$negative, SplitRatio = sr)\nbreddit_test <- subset(b_reddit_predict, breddit_split == TRUE)\nbreddit_train <- subset(b_reddit_predict, breddit_split == FALSE)\n\n#Bing both\nbforandred_split <- sample.split(b_forandred_predict$negative, SplitRatio = sr)\nbforandred_test <- subset(b_forandred_predict, bforandred_split == TRUE)\nbforandred_train <- subset(b_forandred_predict, bforandred_split == FALSE)\n\n#Afinn Forums\naforum_split <- sample.split(a_forum_predict$negative, SplitRatio = sr)\naforum_test <- subset(a_forum_predict, aforum_split == TRUE)\naforum_train <- subset(a_forum_predict, aforum_split == FALSE)\n\n#Afinn Reddit\nareddit_split <- sample.split(a_reddit_predict$negative, SplitRatio = sr)\nareddit_test <- subset(a_reddit_predict, areddit_split == TRUE)\nareddit_train <- subset(a_reddit_predict, areddit_split == FALSE)\n\n#Afinn Both\naforandred_split <- sample.split(a_forandred_predict$negative, SplitRatio = sr)\naforandred_test <- subset(a_forandred_predict, aforandred_split == TRUE)\naforandred_train <- subset(a_forandred_predict, aforandred_split == FALSE)\n\n#----------------Model Functions----------------#\n#First model created. Automatic. No validation used. Default values used.\nCARTMODELMAKER <- function(traindata) {\n  cartmodel1 <- rpart(negative~., data = traindata, method = \"class\")\n  return(cartmodel1)\n}\n\n#Second Model using cross validation. \n\n#First set folds and cross validation method. Then determine increments.\nfitOWControl = trainControl(method=\"cv\",number=10)\ncartGrid <- expand.grid(.cp=(1:50)*0.00001)\n\n#function to find the best cp\ncpmaker <- function(traindata,fold,increment) {\n  fitOWControl = trainControl(method=\"cv\",number=fold)\n  cartGrid <- expand.grid(.cp=(1:50)*increment)\n  cpvalue <- train(negative ~., data=traindata, method=\"rpart\", trControl=fitOWControl, tuneGrid=cartGrid)\n  return(cpvalue)\n}\n\n#build the model using results from CARTMODELTWO\nCARTMODEL2 <- function(traindata, cp) {\n  cartmodel2train <-  rpart(negative ~., data=traindata, method=\"class\",control=rpart.control(cp=cp))\n}\n\n#Third Model (Random Forest)\nRFMODEL <- function(trainingset) {\n  randomforestmodel <- randomForest(negative ~., data = trainingset)\n}\n\n\n#Function to test the model with test data\nCARTMODELTEST <- function(model,testdata) {\n  predictmodel <- predict(model, newdata=testdata, type=\"class\")\n  return(predictmodel)\n}\n\n#Function to show the results\ntablechecker <- function(testdata, modelresults) {\n  tablecheck <- table(testdata$negative, modelresults)\n  confusionMatrix(tablecheck)\n}\n\n#----------------1st Model (Automatic), Testing----------------#\n\n#----------Bing Test----------#\n#Model using the training set\nbingforummodel1 <- CARTMODELMAKER(bforum_train)\nbingredditmodel1 <- CARTMODELMAKER(breddit_train)\nbingforandredmode1l <- CARTMODELMAKER(bforandred_train)\nprp(bingforummodel1)\nprp(bingredditmodel1)\nprp(bingforummodel1)\n\n#Test the model using test set\nbingforumtest1 <- CARTMODELTEST(bingforummodel1, bforum_test)\nbingreddittest1 <- CARTMODELTEST(bingredditmodel1, breddit_test)\nbingforandredtest1 <- CARTMODELTEST(bingforandredmode1l, bforandred_test)\n\n\n#----------Afinn Test----------#\nafinnforummodel1 <- CARTMODELMAKER(aforum_train)\nafinnredditmodel1 <- CARTMODELMAKER(areddit_train)\nafinnforandredmode1l <- CARTMODELMAKER(aforandred_train)\nprp(afinnforummodel1)\nprp(afinnredditmodel1)\nprp(afinnforandredmode1l)\n\n#Test the model using test set\nafinnforumtest1 <- CARTMODELTEST(afinnforummodel1, aforum_test)\nafinnreddittest1 <- CARTMODELTEST(afinnredditmodel1, areddit_test)\nafinnforandredtest1 <- CARTMODELTEST(afinnforandredmode1l, aforandred_test)\n\n#----------------2nd Model (Cross Validated), Testing----------------#\n\n#----------Bing Test----------#\n#Figure out the cp values. May take a minute to find values\ncpbforums <- cpmaker(bforum_train, 10, 0.002)\ncpbreddit <- cpmaker(breddit_train, 10, 0.002)\ncpbforandred <- cpmaker(bforandred_train, 10, 0.001)\ncpbforums\ncpbreddit\ncpbforandred\n\n#Create models with new cp values\nbingforummodel2 <- CARTMODEL2(bforum_train, 0.002)\nbingredditmodel2 <- CARTMODEL2(breddit_train, 0.002)\nbingforandredmodel2 <- CARTMODEL2(bforandred_train, 0.003)\nprp(bingforummodel2)\nprp(bingredditmodel2)\nprp(bingforandredmodel2)\n\n#Test the models \nbingforumtest2 <- CARTMODELTEST(bingforummodel2, bforum_test)\nbingreddittest2 <- CARTMODELTEST(bingredditmodel2, breddit_test)\nbingforandredtest2 <- CARTMODELTEST(bingforandredmodel2, bforandred_test)\n\n\n#----------Afinn Test----------#\n#Figure out the cp values. May take a minute to find values\ncpaforums <- cpmaker(aforum_train, 10, 0.0001)\ncpareddit <- cpmaker(areddit_train, 10, 0.0001)\ncpaforandred <- cpmaker(aforandred_train, 10, 0.0001)\ncpaforums\ncpareddit\ncpaforandred\n\n#Create models with new cp values\nafinnforummodel2 <- CARTMODEL2(aforum_train, 0.0028)\nafinnredditmodel2 <- CARTMODEL2(areddit_train, 0.0041)\nafinnforandredmodel2 <- CARTMODEL2(aforandred_train, 0.0012)\nprp(afinnforummodel2)\nprp(afinnredditmodel2)\nprp(afinnforandredmodel2)\n\n#Test the models \nafinnforumtest2 <- CARTMODELTEST(afinnforummodel2, aforum_test)\nafinnreddittest2 <- CARTMODELTEST(afinnredditmodel2, areddit_test)\nafinnforandredtest2 <- CARTMODELTEST(afinnforandredmodel2, aforandred_test)\n\n#----------------3rd Model (Random Forest), Testing----------------#\n#!!!!!!!!!!!!WARNING! TAKES A LONG TIME TO RUN!!!!!!\n\nbingforummodel3 <- RFMODEL(bforum_train)\nbingredditmodel3 <- RFMODEL(breddit_train)\nbingforandredmodel3 <- RFMODEL(bforandred_train)\n\nafinnforummodel3 <- RFMODEL(aforum_train)\nafinnredditmodel3 <- RFMODEL(areddit_train)\nafinnforandredmodel3 <- RFMODEL(aforandred_train)\n\n#Test the models \nbingforumtest3 <- CARTMODELTEST(bingforummodel3, bforum_test)\nbingreddittest3 <- CARTMODELTEST(bingredditmodel3, breddit_test)\nbingforandredtest3 <- CARTMODELTEST(bingforandredmodel3, bforandred_test)\nafinnforumtest3 <- CARTMODELTEST(afinnforummodel3, aforum_test)\nafinnreddittest3 <- CARTMODELTEST(afinnredditmodel3, areddit_test)\nafinnforandredtest3 <- CARTMODELTEST(afinnforandredmodel3, aforandred_test)\n\n\n#-------------------------Compare Models-------------------------#\n\n#Forum Models (bing)\ntablechecker(bforum_test, bingforumtest1)\ntablechecker(bforum_test, bingforumtest2)\ntablechecker(bforum_test, bingforumtest3)\n\n#Reddit Models (bing)\ntablechecker(breddit_test, bingreddittest1)\ntablechecker(breddit_test, bingreddittest2)\ntablechecker(breddit_test, bingreddittest3)\n\n#Combined Forum & Reddit Models (bing)\ntablechecker(bforandred_test, bingforandredtest1)\ntablechecker(bforandred_test, bingforandredtest2)\ntablechecker(bforandred_test, bingforandredtest3)\n\n#Forum Models (afinn)\ntablechecker(aforum_test, afinnforumtest1)\ntablechecker(aforum_test, afinnforumtest2)\ntablechecker(aforum_test, afinnforumtest3)\n\n#Reddit Models (afinn)\ntablechecker(areddit_test, afinnreddittest1)\ntablechecker(areddit_test, afinnreddittest2)\ntablechecker(areddit_test, afinnreddittest3)\n\n#Combined Forum & Reddit Models (afinn)\ntablechecker(aforandred_test, afinnforandredtest1)\ntablechecker(aforandred_test, afinnforandredtest2)\ntablechecker(aforandred_test, afinnforandredtest3)\n```",
    "created" : 1515729134010.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2759578966",
    "id" : "FA577B5F",
    "lastKnownWriteTime" : 1516062296,
    "last_content_update" : 1516062296826,
    "path" : "~/SBCapstone/Final Project Files/Reports/machine_learning.Rmd",
    "project_path" : "Final Project Files/Reports/machine_learning.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}