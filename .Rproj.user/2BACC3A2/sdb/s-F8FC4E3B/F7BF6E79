{
    "collab_server" : "",
    "contents" : "library(dplyr)\nlibrary(tidytext)\nlibrary(ggplot2)\nlibrary(wordcloud)\nlibrary(reshape2)\nlibrary(RCurl)\n\n#read owforums data into R. Ensure they are not factors\nreddit <- read.csv(text=getURL(\"https://raw.githubusercontent.com/ujumqin/SB_CapstoneProject/master/Final%20Project%20Files/OW%20Data/Raw%20Files/reddit12_22.csv\"), stringsAsFactors = FALSE)\n#reddit <- read.csv(\"reddit12_22.csv\", stringsAsFactors = FALSE)\ntwitter <- read.csv(text=getURL(\"https://raw.githubusercontent.com/ujumqin/SB_CapstoneProject/master/Final%20Project%20Files/OW%20Data/Raw%20Files/OWT_12-22.csv\"), stringsAsFactors = FALSE)\n#twitter <- read.csv(\"OWT_12-22.csv\", stringsAsFactors = FALSE)\nforums <- read.csv(text=getURL(\"https://raw.githubusercontent.com/ujumqin/SB_CapstoneProject/master/Final%20Project%20Files/OW%20Data/Raw%20Files/OWFORUMS12_22_FINAL.csv\"), stringsAsFactors = FALSE)\n#forums <- read.csv(\"OWFORUMS12_22_FINAL.csv\", stringsAsFactors = FALSE)\nall <- read.csv(text=getURL(\"https://raw.githubusercontent.com/ujumqin/SB_CapstoneProject/master/Final%20Project%20Files/OW%20Data/Raw%20Files/all.csv\"), stringsAsFactors = FALSE)\nwithouttwitter <- read.csv(text=getURL(\"https://raw.githubusercontent.com/ujumqin/SB_CapstoneProject/master/Final%20Project%20Files/OW%20Data/Raw%20Files/WithoutTwitter_FINAL.csv\"), stringsAsFactors = FALSE)\n\n\n#duplicating the text column so we have a copy of the text. this text is used to group\nreddit$text_topic <- reddit$X.text.\ntwitter$text_topic <- twitter$text\nforums$text_topic <- forums$text\nall$text_topic <- all$text\nwithouttwitter$text_topic <- withouttwitter$text\n\n#-------------------------Tokenize Text-------------------------\n#tokenize the text column for reddit\ntidy_reddit <- reddit %>%\n  group_by(text_topic) %>%\n  dplyr::mutate(linenumber = row_number()) %>%\n  unnest_tokens(word, X.text.) %>%\n  ungroup()\n\n#tokenize the text column for twitter\ntidy_twitter <- twitter %>%\n  group_by(text_topic) %>%\n  dplyr::mutate(linenumber = row_number()) %>%\n  unnest_tokens(word, text) %>%\n  ungroup()\n\n#tokenize the text column for forums\ntidy_forums <- forums %>%\n  group_by(X.) %>%\n  dplyr::mutate(linenumber = row_number()) %>%\n  unnest_tokens(word, text) %>%\n  ungroup()\n\ntidy_all <- all %>%\n  group_by(X.) %>%\n  dplyr::mutate(linenumber = row_number()) %>%\n  unnest_tokens(word, text) %>%\n  ungroup()\n\ntidy_notwitter <- withouttwitter %>%\n  group_by(X.) %>%\n  dplyr::mutate(linenumber = row_number()) %>%\n  unnest_tokens(word, text) %>%\n  ungroup()\n\n#-------------------------Bing Sentiment-------------------------\nreddit_bing <- tidy_reddit %>%\n  inner_join(get_sentiments(\"bing\")) %>%\n  count(word, sentiment, sort = TRUE) %>%\n  ungroup()\n\ntwitter_bing <- tidy_twitter %>%\n  inner_join(get_sentiments(\"bing\")) %>%\n  count(word, sentiment, sort = TRUE) %>%\n  ungroup()\n\nforum_bing <- tidy_forums %>%\n  inner_join(get_sentiments(\"bing\")) %>%\n  count(word, sentiment, sort = TRUE) %>%\n  ungroup()\n\nall_bing <- tidy_all %>%\n  inner_join(get_sentiments(\"bing\")) %>%\n  count(word, sentiment, sort = TRUE) %>%\n  ungroup()\n\nwithouttwitter_bing <- tidy_notwitter %>%\n  inner_join(get_sentiments(\"bing\")) %>%\n  count(word, sentiment, sort = TRUE) %>%\n  ungroup()\n\n\n#-------------------------Plotting Data (Bing)-------------------------\nreddit_bing %>%\n  group_by(sentiment) %>%\n  top_n(10) %>%\n  ungroup() %>%\n  mutate(word = reorder(word, n)) %>%\n  ggplot(aes(word, n, fill = sentiment)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~sentiment, scales = \"free_y\") +\n  labs(y = \"Reddit Most Used Sentiment Words\",\n       x = NULL) +\n  coord_flip()\n\ntwitter_bing %>%\n  group_by(sentiment) %>%\n  top_n(10) %>%\n  ungroup() %>%\n  mutate(word = reorder(word, n)) %>%\n  ggplot(aes(word, n, fill = sentiment)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~sentiment, scales = \"free_y\") +\n  labs(y = \"Twitter Most Used Sentiment Words\",\n       x = NULL) +\n  coord_flip()\n\nforum_bing %>%\n  group_by(sentiment) %>%\n  top_n(10) %>%\n  ungroup() %>%\n  mutate(word = reorder(word, n)) %>%\n  ggplot(aes(word, n, fill = sentiment)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~sentiment, scales = \"free_y\") +\n  labs(y = \"Overwatch Forums Most Used Sentiment Words\",\n       x = NULL) +\n  coord_flip()\n\nall_bing %>%\n  group_by(sentiment) %>%\n  top_n(10) %>%\n  ungroup() %>%\n  mutate(word = reorder(word, n)) %>%\n  ggplot(aes(word, n, fill = sentiment)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~sentiment, scales = \"free_y\") +\n  labs(y = \"Most Used Sentiment Words By Overwatch Community\",\n       x = NULL) +\n  coord_flip()\n\nwithouttwitter_bing %>%\n  group_by(sentiment) %>%\n  top_n(10) %>%\n  ungroup() %>%\n  mutate(word = reorder(word, n)) %>%\n  ggplot(aes(word, n, fill = sentiment)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~sentiment, scales = \"free_y\") +\n  labs(y = \"Most Used Sentiment Words By Overwatch Community\",\n       x = NULL) +\n  coord_flip()\n#-------------------------nrc Sentiment-------------------------\nreddit_nrc <- tidy_reddit %>%\n  inner_join(get_sentiments(\"nrc\"))\n\ntwitter_nrc <- tidy_twitter %>%\n  inner_join(get_sentiments(\"nrc\"))\n\nforum_nrc <- tidy_forums %>%\n  inner_join(get_sentiments(\"nrc\"))\n\nall_nrc <- tidy_all %>%\n  inner_join(get_sentiments(\"nrc\"))\n\nwithouttwitter_nrc <- tidy_all %>%\n  inner_join(get_sentiments(\"nrc\"))\n\n#-------------------------Plotting Data (nrc)-------------------------\nggplot(reddit_nrc, aes(x=\"\", fill=sentiment)) +\n  geom_bar(width = 1) +\n  ggtitle(\"reddit\") \n\nreddit_bar\n\nreddit_bar + coord_polar(\"y\")\n\nggplot(forum_nrc, aes(x=\"\", fill=sentiment)) +\n  geom_bar(width = 1) +\n  ggtitle(\"Overwatch Forums\") \n\nforum_bar\n\nforum_bar + coord_polar(\"y\")\n\n\nggplot(twitter_nrc, aes(x=sentiment)) +\n  geom_bar(aes(y=..count.., fill =..count..)) +\n  theme(axis.text.x = element_text(size = 10, angle = 45, hjust = 1, vjust = 1)) +\n  ggtitle(\"Twitter\") +\n  coord_cartesian(ylim = c(0,11000), expand = TRUE)\n\nggplot(forum_nrc, aes(x=sentiment)) +\n  geom_bar(aes(y=..count.., fill =..count..)) +\n  theme(axis.text.x = element_text(size = 10, angle = 45, hjust = 1, vjust = 1)) +\n  ggtitle(\"Overwatch Forums\") +\n  coord_cartesian(ylim = c(0,11000), expand = TRUE)\n\nggplot(withouttwitter_nrc, aes(x=sentiment)) +\n  geom_bar(aes(y=..count.., fill =..count..)) +\n  theme(axis.text.x = element_text(size = 10, angle = 45, hjust = 1, vjust = 1)) +\n  ggtitle(\"All Communities\") +\n  coord_cartesian(ylim = c(0,24000), expand = TRUE)\n  \n#-------------------------afinn Sentiment-------------------------\nreddit_afinn <- tidy_reddit %>%\n  inner_join(get_sentiments(\"afinn\"))\n\ntwitter_afinn <- tidy_twitter %>%\n  inner_join(get_sentiments(\"afinn\"))\n\nforum_afinn <- tidy_forums %>%\n  inner_join(get_sentiments(\"afinn\"))\n\nall_afinn <- tidy_all %>%\n  inner_join(get_sentiments(\"afinn\"))\n\nwithouttwitter_afinn <- tidy_notwitter %>%\n  inner_join(get_sentiments(\"afinn\"))\n\n#-------------------------Plotting data (Afinn)-------------------------\n\nggplot(twitter_afinn, aes(x=score)) +\n  geom_bar(aes(y=..count.., fill= ..count..)) + \n  labs(x=\"afinn score\") +\n  xlab(\"afinn score\")+\n  coord_cartesian(ylim = c(0,7000), expand = TRUE) +\n  ggtitle(\"twitter\") +\n  scale_x_continuous(breaks = -5:5) \n\nggplot(forum_afinn, aes(x=score)) +\n  geom_bar(aes(y=..count.., fill=..count..)) + \n  labs(x=\"afinn score\") +\n  xlab(\"afinn score\")+\n  coord_cartesian(ylim = c(0,7000), expand = TRUE)+\n  ggtitle(\"Overwatch Forums\") +\n  scale_x_continuous(breaks = -5:5) \n\nggplot(reddit_afinn, aes(x=score)) +\n  geom_bar(aes(y=..count.., fill=..count..)) + \n  labs(x=\"afinn score\") +\n  xlab(\"afinn score\")  +\n  coord_cartesian(ylim = c(0,7000), expand = TRUE)+\n  ggtitle(\"Reddit\") +\n  scale_x_continuous(breaks = -5:5) \n\nggplot(withouttwitter_afinn, aes(x=score)) +\n  geom_bar(aes(y=..count.., fill=..count..)) + \n  labs(x=\"afinn score\") +\n  xlab(\"afinn score\")  +\n  coord_cartesian(ylim = c(0,13000), expand = TRUE)+\n  ggtitle(\"All\") +\n  scale_x_continuous(breaks = -5:5) \n\n#-------------------------Word Clouds-------------------------\n\ntidy_forums %>%\n  anti_join(stop_words) %>%\n  count(word) %>%\n  with(wordcloud(word, n, max.words = 50))\n\ntidy_reddit %>%\n  anti_join(stop_words) %>%\n  count(word) %>%\n  with(wordcloud(word, n, max.words = 50))\n\ntidy_twitter %>%\n  anti_join(stop_words) %>%\n  count(word) %>%\n  with(wordcloud(word, n, max.words = 50))\n\ntidy_all %>%\n  anti_join(stop_words) %>%\n  count(word) %>%\n  with(wordcloud(word, n, max.words = 50))\n\ntidy_notwitter %>%\n  anti_join(stop_words) %>%\n  count(word) %>%\n  with(wordcloud(word, n, max.words = 50))\n\n#-------------------------Word Clouds (negative vs positive)-------------------------\npar(mfrow=c(2,2))\n\ntidy_forums %>%\n  inner_join(get_sentiments(\"bing\")) %>%\n  count(word, sentiment, sort = TRUE) %>%\n  acast(word ~ sentiment, value.var = \"n\", fill = 0) %>%\n  comparison.cloud(colors = c(\"gray20\", \"gray80\"),\n                   max.words = 80)\n\n tidy_reddit %>%\n  inner_join(get_sentiments(\"bing\")) %>%\n  count(word, sentiment, sort = TRUE) %>%\n  acast(word ~ sentiment, value.var = \"n\", fill = 0) %>%\n  comparison.cloud(colors = c(\"gray20\", \"gray80\"),\n                   max.words = 80)\n\ntidy_twitter %>%\n  inner_join(get_sentiments(\"bing\")) %>%\n  count(word, sentiment, sort = TRUE) %>%\n  acast(word ~ sentiment, value.var = \"n\", fill = 0) %>%\n  comparison.cloud(colors = c(\"gray20\", \"gray80\"),\n                   max.words = 80)\n\ntidy_notwitter %>%\n  inner_join(get_sentiments(\"bing\")) %>%\n  count(word, sentiment, sort = TRUE) %>%\n  acast(word ~ sentiment, value.var = \"n\", fill = 0) %>%\n  comparison.cloud(colors = c(\"gray20\", \"gray80\"),\n                   max.words = 80)\n",
    "created" : 1516060390702.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2839964840",
    "id" : "F7BF6E79",
    "lastKnownWriteTime" : 1515306956,
    "last_content_update" : 1515306956,
    "path" : "~/SBCapstone/Final Project Files/Analyzer/exploratory_statistics.R",
    "project_path" : "Final Project Files/Analyzer/exploratory_statistics.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}